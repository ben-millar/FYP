{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.7.0\n",
    "#!pip install gym\n",
    "#!pip install keras\n",
    "#!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from VMAllocationEnvironment import VMAllocationEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-94493e8e008d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVMAllocationEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Documents\\Computer Games Development\\Year 4\\FYP\\Reinforcement Bin Packing\\VM Allocation\\VMAllocationEnvironment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_bins, capacity)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_vms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         low = np.hstack((\n",
      "\u001b[1;32mD:\\Documents\\Computer Games Development\\Year 4\\FYP\\Reinforcement Bin Packing\\VM Allocation\\VMAllocationEnvironment.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m             )).reshape(self.num_bins + 1, 4)\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetNewItem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\Computer Games Development\\Year 4\\FYP\\Reinforcement Bin Packing\\VM Allocation\\VMAllocationEnvironment.py\u001b[0m in \u001b[0;36mgetNewItem\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetNewItem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_vms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[0mnext_item\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_vms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# We ignore the final, popularity, value for now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_bins\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_item\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "env = VMAllocationEnvironment(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run control test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-8275\n",
      "Total steps: 405\n",
      "Accuracy of placed items: 9.66%\n",
      "Items placed correctly first time: 8.4%\n",
      "[('placed', 34), ('misplaced', 318), ('discarded', 53)]\n",
      "\n",
      "Episode:2 Score:-26405\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.37%\n",
      "Items placed correctly first time: 3.1%\n",
      "[('placed', 31), ('misplaced', 889), ('discarded', 80)]\n",
      "\n",
      "Episode:3 Score:-25656\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.96%\n",
      "Items placed correctly first time: 3.6%\n",
      "[('placed', 36), ('misplaced', 873), ('discarded', 91)]\n",
      "\n",
      "Episode:4 Score:-20915\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 5.12%\n",
      "Items placed correctly first time: 4.6%\n",
      "[('placed', 46), ('misplaced', 852), ('discarded', 102)]\n",
      "\n",
      "Episode:5 Score:-26441\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.1%\n",
      "Items placed correctly first time: 3.8%\n",
      "[('placed', 38), ('misplaced', 888), ('discarded', 74)]\n",
      "\n",
      "Episode:6 Score:-29334\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.7%\n",
      "Items placed correctly first time: 4.3%\n",
      "[('placed', 43), ('misplaced', 871), ('discarded', 86)]\n",
      "\n",
      "Episode:7 Score:-21748\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.16%\n",
      "Items placed correctly first time: 3.8%\n",
      "[('placed', 38), ('misplaced', 876), ('discarded', 86)]\n",
      "\n",
      "Episode:8 Score:-19795\n",
      "Total steps: 868\n",
      "Accuracy of placed items: 5.03%\n",
      "Items placed correctly first time: 4.61%\n",
      "[('placed', 40), ('misplaced', 755), ('discarded', 73)]\n",
      "\n",
      "Episode:9 Score:-22366\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.79%\n",
      "Items placed correctly first time: 3.4%\n",
      "[('placed', 34), ('misplaced', 863), ('discarded', 103)]\n",
      "\n",
      "Episode:10 Score:-22795\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.6%\n",
      "Items placed correctly first time: 4.2%\n",
      "[('placed', 42), ('misplaced', 871), ('discarded', 87)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS = 1000\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    steps = 0\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    session_info = Counter({ 'placed':0, 'misplaced':0, 'discarded':0 })\n",
    "    \n",
    "    while not done and steps < MAX_STEPS:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        steps += 1\n",
    "        session_info += Counter(info)\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "    print('Total steps: {}'.format(steps))\n",
    "    \n",
    "    # Counter method sometimes shuffles keys; this returns the order\n",
    "    ordered_info = \\\n",
    "        sorted(dict(session_info).items(), key=lambda x:x[0], reverse=True)\n",
    "    \n",
    "    placed, misplaced, discarded = ordered_info[:]\n",
    "    accuracy = (placed[1] / (placed[1] + misplaced[1])) * 100\n",
    "    print('Accuracy of placed items: {:.3}%'.format(accuracy))\n",
    "    \n",
    "    first_time = (placed[1] / (placed[1] + misplaced[1] + discarded[1])) * 100\n",
    "    print('Items placed correctly first time: {:.3}%'.format(first_time))\n",
    "    \n",
    "    print(ordered_info)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    #print(env.logs)\n",
    "    #control_data.log(env)\n",
    "    #env.logs = { 'placed':0, 'misplaced':0, 'discarded':0 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will throw an error if these don't exist\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BinPacking2D(num_bins=10, capacity=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_6\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 280  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007914768 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.39       |\n",
      "|    explained_variance   | -0.00159    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1e+05     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    value_loss           | 2.14e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008729046 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 9.35e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.29e+04    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    value_loss           | 1.28e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 460         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007990466 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.36       |\n",
      "|    explained_variance   | 5.98e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.13e+04    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 1.43e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011180237 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 3.81e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.54e+04    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 8.69e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 514        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01191761 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.28      |\n",
      "|    explained_variance   | 2.63e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.89e+04   |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0208    |\n",
      "|    value_loss           | 5.78e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010740053 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | 9.24e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+04    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 2.89e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116027575 |\n",
      "|    clip_fraction        | 0.0994       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.22        |\n",
      "|    explained_variance   | 1.75e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.46e+04     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    value_loss           | 2.07e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014274197 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 1.67e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.58e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 1.02e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014599454 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 1.5e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.42e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 8.03e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 553         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011040016 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 9.6e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    value_loss           | 5.87e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020723503 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 1.64e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 2.6e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012252329 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 1.35e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 565         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736261 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 9.66e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 381         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 488         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012997843 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 7.39e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 280         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    value_loss           | 399         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013518563 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 3.4e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 261         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 592         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 564          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011280754 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.17        |\n",
      "|    explained_variance   | 3.81e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 2.25e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 565          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009821771 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 1.55e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 363          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 598          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 565          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058588665 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 2.98e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 369          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021008616 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.17        |\n",
      "|    explained_variance   | 1.19e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011303699 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 95.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007951292 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 3.58e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 658         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016323373 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 7.15e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.3        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 557          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006069033 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.0937       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 287          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 558          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149136465 |\n",
      "|    clip_fraction        | 0.292        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0185      |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 0.492        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 557         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013064921 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00407    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 0.397       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 557         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018277839 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0222     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 557        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00995045 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.99      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0405     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00462   |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 556          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020931265 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 94.5         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 555           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 110           |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9788196e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.03         |\n",
      "|    explained_variance   | 0.381         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 411           |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000266     |\n",
      "|    value_loss           | 1.12e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 555           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 114           |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1071348e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.08         |\n",
      "|    explained_variance   | 0.00375       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.51e+03      |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.00022      |\n",
      "|    value_loss           | 3.6e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 554           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 118           |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014230394 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.03         |\n",
      "|    explained_variance   | 0.0525        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 88.1          |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.000756     |\n",
      "|    value_loss           | 361           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012995178 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016112734 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.363       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011336904 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013672939 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0473      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    value_loss           | 0.744       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014425699 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00739     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    value_loss           | 0.482       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013763055 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0933      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 0.337       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007065276 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.9         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 550           |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 148           |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043622075 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.07         |\n",
      "|    explained_variance   | 0.51          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.45e+03      |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    value_loss           | 3.13e+03      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a169a60eb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved Models', '2D_Bin_Packing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-10257\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.73%\n",
      "Items placed correctly first time: 3.5%\n",
      "[('placed', 35), ('misplaced', 705), ('discarded', 260)]\n",
      "\n",
      "Episode:2 Score:-14833\n",
      "Total steps: 992\n",
      "Accuracy of placed items: 4.82%\n",
      "Items placed correctly first time: 4.33%\n",
      "[('placed', 43), ('misplaced', 849), ('discarded', 100)]\n",
      "\n",
      "Episode:3 Score:-4941\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 10.3%\n",
      "Items placed correctly first time: 3.9%\n",
      "[('placed', 39), ('misplaced', 340), ('discarded', 621)]\n",
      "\n",
      "Episode:4 Score:-13389\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.44%\n",
      "Items placed correctly first time: 4.0%\n",
      "[('placed', 40), ('misplaced', 860), ('discarded', 100)]\n",
      "\n",
      "Episode:5 Score:-773\n",
      "Total steps: 233\n",
      "Accuracy of placed items: 26.1%\n",
      "Items placed correctly first time: 17.2%\n",
      "[('placed', 40), ('misplaced', 113), ('discarded', 80)]\n",
      "\n",
      "Episode:6 Score:-11410\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.17%\n",
      "Items placed correctly first time: 3.9%\n",
      "[('placed', 39), ('misplaced', 896), ('discarded', 65)]\n",
      "\n",
      "Episode:7 Score:-5202\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 8.27%\n",
      "Items placed correctly first time: 4.1%\n",
      "[('placed', 41), ('misplaced', 455), ('discarded', 504)]\n",
      "\n",
      "Episode:8 Score:-7287\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 7.48%\n",
      "Items placed correctly first time: 4.6%\n",
      "[('placed', 46), ('misplaced', 569), ('discarded', 385)]\n",
      "\n",
      "Episode:9 Score:-17931\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.76%\n",
      "Items placed correctly first time: 3.4%\n",
      "[('placed', 34), ('misplaced', 870), ('discarded', 96)]\n",
      "\n",
      "Episode:10 Score:-8110\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.83%\n",
      "Items placed correctly first time: 3.5%\n",
      "[('placed', 35), ('misplaced', 878), ('discarded', 87)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS = 1000\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    steps = 0\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    session_info = Counter({ 'placed':0, 'misplaced':0, 'discarded':0 })\n",
    "    \n",
    "    while not done and steps < MAX_STEPS:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        steps += 1\n",
    "        session_info += Counter(info)\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "    print('Total steps: {}'.format(steps))\n",
    "    \n",
    "    # Counter method sometimes shuffles keys; this returns the order\n",
    "    ordered_info = \\\n",
    "        sorted(dict(session_info).items(), key=lambda x:x[0], reverse=True)\n",
    "    \n",
    "    placed, misplaced, discarded = ordered_info[:]\n",
    "    accuracy = (placed[1] / (placed[1] + misplaced[1])) * 100\n",
    "    print('Accuracy of placed items: {:.3}%'.format(accuracy))\n",
    "    \n",
    "    first_time = (placed[1] / (placed[1] + misplaced[1] + discarded[1])) * 100\n",
    "    print('Items placed correctly first time: {:.3}%'.format(first_time))\n",
    "    \n",
    "    print(ordered_info)\n",
    "    \n",
    "    print()\n",
    "    #real_data.log(env)\n",
    "    #env.logs = { 'placed':0, 'misplaced':0, 'discarded':0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

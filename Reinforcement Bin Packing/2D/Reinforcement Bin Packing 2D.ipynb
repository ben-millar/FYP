{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.7.0\n",
    "#!pip install gym\n",
    "#!pip install keras\n",
    "#!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from BinPackingEnvironment2D import BinPacking2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BinPacking2D(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run control test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-19443\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.99%\n",
      "Items placed correctly first time: 3.6%\n",
      "[('placed', 36), ('misplaced', 867), ('discarded', 97)]\n",
      "\n",
      "Episode:2 Score:-18411\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.57%\n",
      "Items placed correctly first time: 4.1%\n",
      "[('placed', 41), ('misplaced', 856), ('discarded', 103)]\n",
      "\n",
      "Episode:3 Score:-24898\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.23%\n",
      "Items placed correctly first time: 3.9%\n",
      "[('placed', 39), ('misplaced', 883), ('discarded', 78)]\n",
      "\n",
      "Episode:4 Score:-21682\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.88%\n",
      "Items placed correctly first time: 3.5%\n",
      "[('placed', 35), ('misplaced', 868), ('discarded', 97)]\n",
      "\n",
      "Episode:5 Score:-18271\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.34%\n",
      "Items placed correctly first time: 3.9%\n",
      "[('placed', 39), ('misplaced', 860), ('discarded', 101)]\n",
      "\n",
      "Episode:6 Score:-26122\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.71%\n",
      "Items placed correctly first time: 3.4%\n",
      "[('placed', 34), ('misplaced', 883), ('discarded', 83)]\n",
      "\n",
      "Episode:7 Score:-23125\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.87%\n",
      "Items placed correctly first time: 3.5%\n",
      "[('placed', 35), ('misplaced', 870), ('discarded', 95)]\n",
      "\n",
      "Episode:8 Score:-21559\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 4.03%\n",
      "Items placed correctly first time: 3.7%\n",
      "[('placed', 37), ('misplaced', 882), ('discarded', 81)]\n",
      "\n",
      "Episode:9 Score:-24851\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 3.98%\n",
      "Items placed correctly first time: 3.6%\n",
      "[('placed', 36), ('misplaced', 868), ('discarded', 96)]\n",
      "\n",
      "Episode:10 Score:-9156\n",
      "Total steps: 544\n",
      "Accuracy of placed items: 6.99%\n",
      "Items placed correctly first time: 6.43%\n",
      "[('placed', 35), ('misplaced', 466), ('discarded', 43)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS = 1000\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    steps = 0\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    session_info = Counter({ 'placed':0, 'misplaced':0, 'discarded':0 })\n",
    "    \n",
    "    while not done and steps < MAX_STEPS:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        steps += 1\n",
    "        session_info += Counter(info)\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "    print('Total steps: {}'.format(steps))\n",
    "    \n",
    "    # Counter method sometimes shuffles keys; this returns the order\n",
    "    ordered_info = \\\n",
    "        sorted(dict(session_info).items(), key=lambda x:x[0], reverse=True)\n",
    "    \n",
    "    placed, misplaced, discarded = ordered_info[:]\n",
    "    accuracy = (placed[1] / (placed[1] + misplaced[1])) * 100\n",
    "    print('Accuracy of placed items: {:.3}%'.format(accuracy))\n",
    "    \n",
    "    first_time = (placed[1] / (placed[1] + misplaced[1] + discarded[1])) * 100\n",
    "    print('Items placed correctly first time: {:.3}%'.format(first_time))\n",
    "    \n",
    "    print(ordered_info)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    #print(env.logs)\n",
    "    #control_data.log(env)\n",
    "    #env.logs = { 'placed':0, 'misplaced':0, 'discarded':0 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will throw an error if these don't exist\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BinPacking2D(num_bins=10, capacity=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_3\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 78   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 26   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 144          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063706646 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.4         |\n",
      "|    explained_variance   | -0.000475    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.28e+04     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.007       |\n",
      "|    value_loss           | 1.5e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118175475 |\n",
      "|    clip_fraction        | 0.0738       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.38        |\n",
      "|    explained_variance   | 0.000916     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.3e+04      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 1.3e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 257          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116377035 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.36        |\n",
      "|    explained_variance   | 0.000122     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.5e+04      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 1.46e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00678088 |\n",
      "|    clip_fraction        | 0.0305     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.34      |\n",
      "|    explained_variance   | 4.81e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.43e+04   |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    value_loss           | 7.86e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 347        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01155627 |\n",
      "|    clip_fraction        | 0.0931     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.3       |\n",
      "|    explained_variance   | 3.12e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.79e+04   |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    value_loss           | 7.38e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 386          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126365395 |\n",
      "|    clip_fraction        | 0.0942       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 4.2e-05      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+04     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    value_loss           | 3.32e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 418        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01217579 |\n",
      "|    clip_fraction        | 0.0991     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.25      |\n",
      "|    explained_variance   | 4.48e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.87e+03   |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    value_loss           | 1.88e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 450        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01406897 |\n",
      "|    clip_fraction        | 0.0921     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.21      |\n",
      "|    explained_variance   | 2.38e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.86e+03   |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    value_loss           | 1.48e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 479         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015136454 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 4.46e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.28e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 6.03e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014035119 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 1.67e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.64e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 7.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012520036 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 1.16e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.35e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 4.49e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016442388 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 2.46e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020793412 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 1.52e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 3.56e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011722304 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 1.14e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 871         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 608          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066823214 |\n",
      "|    clip_fraction        | 0.0769       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.23        |\n",
      "|    explained_variance   | 8.34e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 325          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    value_loss           | 761          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 625         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013470244 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 1.85e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.8        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 642        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01587537 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.22      |\n",
      "|    explained_variance   | 9.95e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 250        |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.00787   |\n",
      "|    value_loss           | 523        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006706173 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 2.92e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    value_loss           | 2.3e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 672         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013058443 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 8.05e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 610         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 686        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00756146 |\n",
      "|    clip_fraction        | 0.0378     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.19      |\n",
      "|    explained_variance   | 2.5e-06    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 698        |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.00517   |\n",
      "|    value_loss           | 1.64e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014998769 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 5.3e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013784038 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025423264 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 8.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 736         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020116387 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 2.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 747         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002375271 |\n",
      "|    clip_fraction        | 0.00488     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.0615      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.57        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 758         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001200781 |\n",
      "|    clip_fraction        | 0.00288     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 766          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013453499 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.455        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011496384 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0203     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 783          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023167199 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 790          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017542567 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    value_loss           | 50.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 798           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 82            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091151986 |\n",
      "|    clip_fraction        | 0.00371       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | 0.79          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 12.1          |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    value_loss           | 30.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 803          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023003407 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.151        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000436    |\n",
      "|    value_loss           | 0.1          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 810         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019242257 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 0.0456      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 818         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001889704 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -8.96e-05   |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 825         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020770181 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.53        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 832           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 91            |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073848525 |\n",
      "|    clip_fraction        | 0.004         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.66         |\n",
      "|    explained_variance   | 0.385         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 19.7          |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.00287      |\n",
      "|    value_loss           | 74.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 838          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010620999 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.71        |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 845          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015196991 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 51.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 851          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042116065 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1fc809eb670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved Models', '2D_Bin_Packing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-786\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 57.8%\n",
      "Items placed correctly first time: 5.2%\n",
      "[('placed', 52), ('misplaced', 38), ('discarded', 910)]\n",
      "\n",
      "Episode:2 Score:-912\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 39.3%\n",
      "Items placed correctly first time: 4.6%\n",
      "[('placed', 46), ('misplaced', 71), ('discarded', 883)]\n",
      "\n",
      "Episode:3 Score:-1690\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 8.7%\n",
      "Items placed correctly first time: 4.9%\n",
      "[('placed', 49), ('misplaced', 514), ('discarded', 437)]\n",
      "\n",
      "Episode:4 Score:-1329\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 25.1%\n",
      "Items placed correctly first time: 5.7%\n",
      "[('placed', 57), ('misplaced', 170), ('discarded', 773)]\n",
      "\n",
      "Episode:5 Score:-1037\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 53.9%\n",
      "Items placed correctly first time: 4.8%\n",
      "[('placed', 48), ('misplaced', 41), ('discarded', 911)]\n",
      "\n",
      "Episode:6 Score:-1323\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 18.4%\n",
      "Items placed correctly first time: 4.9%\n",
      "[('placed', 49), ('misplaced', 218), ('discarded', 733)]\n",
      "\n",
      "Episode:7 Score:-1152\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 27.1%\n",
      "Items placed correctly first time: 5.1%\n",
      "[('placed', 51), ('misplaced', 137), ('discarded', 812)]\n",
      "\n",
      "Episode:8 Score:-837\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 38.7%\n",
      "Items placed correctly first time: 5.5%\n",
      "[('placed', 55), ('misplaced', 87), ('discarded', 858)]\n",
      "\n",
      "Episode:9 Score:-611\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 47.1%\n",
      "Items placed correctly first time: 5.7%\n",
      "[('placed', 57), ('misplaced', 64), ('discarded', 879)]\n",
      "\n",
      "Episode:10 Score:-679\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 52.8%\n",
      "Items placed correctly first time: 4.7%\n",
      "[('placed', 47), ('misplaced', 42), ('discarded', 911)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS = 1000\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    steps = 0\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    session_info = Counter({ 'placed':0, 'misplaced':0, 'discarded':0 })\n",
    "    \n",
    "    while not done and steps < MAX_STEPS:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        steps += 1\n",
    "        session_info += Counter(info)\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "    print('Total steps: {}'.format(steps))\n",
    "    \n",
    "    # Counter method sometimes shuffles keys; this returns the order\n",
    "    ordered_info = \\\n",
    "        sorted(dict(session_info).items(), key=lambda x:x[0], reverse=True)\n",
    "    \n",
    "    placed, misplaced, discarded = ordered_info[:]\n",
    "    accuracy = (placed[1] / (placed[1] + misplaced[1])) * 100\n",
    "    print('Accuracy of placed items: {:.3}%'.format(accuracy))\n",
    "    \n",
    "    first_time = (placed[1] / (placed[1] + misplaced[1] + discarded[1])) * 100\n",
    "    print('Items placed correctly first time: {:.3}%'.format(first_time))\n",
    "    \n",
    "    print(ordered_info)\n",
    "    \n",
    "    print()\n",
    "    #real_data.log(env)\n",
    "    #env.logs = { 'placed':0, 'misplaced':0, 'discarded':0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.7.0\n",
    "#!pip install gym\n",
    "#!pip install keras\n",
    "#!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from BinPackingEnvironment2D import BinPacking2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BinPacking2D(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run control test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-25441\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.046%\n",
      "Items placed correctly first time: 0.042%\n",
      "[('placed', 42), ('misplaced', 864), ('discarded', 94)]\n",
      "\n",
      "Episode:2 Score:-22208\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.036%\n",
      "Items placed correctly first time: 0.033%\n",
      "[('placed', 33), ('misplaced', 876), ('discarded', 91)]\n",
      "\n",
      "Episode:3 Score:-25854\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.04%\n",
      "Items placed correctly first time: 0.037%\n",
      "[('placed', 37), ('misplaced', 891), ('discarded', 72)]\n",
      "\n",
      "Episode:4 Score:-19711\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.043%\n",
      "Items placed correctly first time: 0.039%\n",
      "[('placed', 39), ('misplaced', 869), ('discarded', 92)]\n",
      "\n",
      "Episode:5 Score:-24730\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.046%\n",
      "Items placed correctly first time: 0.042%\n",
      "[('placed', 42), ('misplaced', 874), ('discarded', 84)]\n",
      "\n",
      "Episode:6 Score:-27318\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.046%\n",
      "Items placed correctly first time: 0.042%\n",
      "[('placed', 42), ('misplaced', 870), ('discarded', 88)]\n",
      "\n",
      "Episode:7 Score:-22608\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.041%\n",
      "Items placed correctly first time: 0.038%\n",
      "[('placed', 38), ('misplaced', 884), ('discarded', 78)]\n",
      "\n",
      "Episode:8 Score:-20669\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.044%\n",
      "Items placed correctly first time: 0.04%\n",
      "[('placed', 40), ('misplaced', 873), ('discarded', 87)]\n",
      "\n",
      "Episode:9 Score:-22687\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.04%\n",
      "Items placed correctly first time: 0.036%\n",
      "[('placed', 36), ('misplaced', 872), ('discarded', 92)]\n",
      "\n",
      "Episode:10 Score:-24616\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.043%\n",
      "Items placed correctly first time: 0.039%\n",
      "[('placed', 39), ('misplaced', 870), ('discarded', 91)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS = 1000\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    steps = 0\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    session_info = Counter({ 'placed':0, 'misplaced':0, 'discarded':0 })\n",
    "    \n",
    "    while not done and steps < MAX_STEPS:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        steps += 1\n",
    "        session_info += Counter(info)\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "    print('Total steps: {}'.format(steps))\n",
    "    \n",
    "    # Counter method sometimes shuffles keys; this returns the order\n",
    "    ordered_info = \\\n",
    "        sorted(dict(session_info).items(), key=lambda x:x[0], reverse=True)\n",
    "    \n",
    "    placed, misplaced, discarded = ordered_info[:]\n",
    "    accuracy = placed[1] / (placed[1] + misplaced[1])\n",
    "    print('Accuracy of placed items: {:.2}%'.format(accuracy))\n",
    "    \n",
    "    first_time = placed[1] / (placed[1] + misplaced[1] + discarded[1])\n",
    "    print('Items placed correctly first time: {:.2}%'.format(first_time))\n",
    "    \n",
    "    print(ordered_info)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    #print(env.logs)\n",
    "    #control_data.log(env)\n",
    "    #env.logs = { 'placed':0, 'misplaced':0, 'discarded':0 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will throw an error if these don't exist\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BinPacking2D(num_bins=10, capacity=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 202  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 10   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 290          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065387916 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.39        |\n",
      "|    explained_variance   | 2.67e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+05     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 1.93e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 345         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008590005 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.000132    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.31e+04    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    value_loss           | 1.52e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008505068 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.37       |\n",
      "|    explained_variance   | 3.41e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.69e+04    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    value_loss           | 1.23e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011356704 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 1.65e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.59e+04    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 1.16e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 427          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103081595 |\n",
      "|    clip_fraction        | 0.0746       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.3         |\n",
      "|    explained_variance   | 1.19e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.94e+04     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    value_loss           | 6.5e+04      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 443         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011357389 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | 1.15e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+04    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 3.76e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 452         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013819125 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 1.03e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+04    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 2.01e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013734605 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 1.1e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.98e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 1.2e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 464        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01578293 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.23      |\n",
      "|    explained_variance   | 9.12e-06   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.03e+03   |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    value_loss           | 6.98e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142004285 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 8.76e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.01e+03     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    value_loss           | 4.25e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065043066 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 4.29e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    value_loss           | 4.66e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 356         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012903697 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 1.06e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    value_loss           | 667         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011646584 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 8.34e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    value_loss           | 3.36e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073259715 |\n",
      "|    clip_fraction        | 0.223        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 5.42e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 233          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 0.000706     |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 380           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 86            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00059291365 |\n",
      "|    clip_fraction        | 0.00747       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.17         |\n",
      "|    explained_variance   | 2.56e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.45e+03      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | 0.00138       |\n",
      "|    value_loss           | 8.7e+03       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 390         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012432394 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 3.1e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.0011      |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008076816 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 6.56e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010311633 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 6.02e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 745          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011000461 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 2.21e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 536          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 413          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011384276 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 1.37e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 2.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018288918 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 2.38e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 316         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 497         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020722884 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.0123       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 566          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    value_loss           | 946          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 428          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016385126 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.00825      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 203          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    value_loss           | 730          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 434          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014531255 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 9.84e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 612          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 438         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012765212 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.00186     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.04        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 441         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011585446 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 445         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005670611 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0.00554     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 302         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 449          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015193617 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 387          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 451        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02014478 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.09      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0307     |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.000526  |\n",
      "|    value_loss           | 2.4        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 454         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012755826 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.358       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.000704   |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006435064 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 461           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 146           |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079743855 |\n",
      "|    clip_fraction        | 0.00947       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.02         |\n",
      "|    explained_variance   | 0.669         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 80.3          |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.00292      |\n",
      "|    value_loss           | 249           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008783888 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076543456 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    value_loss           | 88.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 472         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017956223 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 0.652       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 475          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023713072 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 478        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 162        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01146444 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.15      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.028     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00183   |\n",
      "|    value_loss           | 0.302      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 479          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152064655 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.17        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.017       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    value_loss           | 0.235        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 482         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016804669 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2224330ad60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved Models', '2D_Bin_Packing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-1797\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.25%\n",
      "Items placed correctly first time: 0.039%\n",
      "[('placed', 39), ('misplaced', 118), ('discarded', 843)]\n",
      "\n",
      "Episode:2 Score:-3998\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.062%\n",
      "Items placed correctly first time: 0.044%\n",
      "[('placed', 44), ('misplaced', 663), ('discarded', 293)]\n",
      "\n",
      "Episode:3 Score:-2856\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.17%\n",
      "Items placed correctly first time: 0.044%\n",
      "[('placed', 44), ('misplaced', 208), ('discarded', 748)]\n",
      "\n",
      "Episode:4 Score:-3151\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.092%\n",
      "Items placed correctly first time: 0.044%\n",
      "[('placed', 44), ('misplaced', 433), ('discarded', 523)]\n",
      "\n",
      "Episode:5 Score:-3011\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.095%\n",
      "Items placed correctly first time: 0.042%\n",
      "[('placed', 42), ('misplaced', 399), ('discarded', 559)]\n",
      "\n",
      "Episode:6 Score:-1120\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.43%\n",
      "Items placed correctly first time: 0.046%\n",
      "[('placed', 46), ('misplaced', 61), ('discarded', 893)]\n",
      "\n",
      "Episode:7 Score:-3569\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.13%\n",
      "Items placed correctly first time: 0.037%\n",
      "[('placed', 37), ('misplaced', 240), ('discarded', 723)]\n",
      "\n",
      "Episode:8 Score:-3976\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.079%\n",
      "Items placed correctly first time: 0.042%\n",
      "[('placed', 42), ('misplaced', 489), ('discarded', 469)]\n",
      "\n",
      "Episode:9 Score:-1227\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.25%\n",
      "Items placed correctly first time: 0.037%\n",
      "[('placed', 37), ('misplaced', 114), ('discarded', 849)]\n",
      "\n",
      "Episode:10 Score:-3163\n",
      "Total steps: 1000\n",
      "Accuracy of placed items: 0.12%\n",
      "Items placed correctly first time: 0.052%\n",
      "[('placed', 52), ('misplaced', 399), ('discarded', 549)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS = 1000\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    steps = 0\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    session_info = Counter({ 'placed':0, 'misplaced':0, 'discarded':0 })\n",
    "    \n",
    "    while not done and steps < MAX_STEPS:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        steps += 1\n",
    "        session_info += Counter(info)\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "    print('Total steps: {}'.format(steps))\n",
    "    \n",
    "    # Counter method sometimes shuffles keys; this returns the order\n",
    "    ordered_info = \\\n",
    "        sorted(dict(session_info).items(), key=lambda x:x[0], reverse=True)\n",
    "    \n",
    "    placed, misplaced, discarded = ordered_info[:]\n",
    "    accuracy = placed[1] / (placed[1] + misplaced[1])\n",
    "    print('Accuracy of placed items: {:.2}%'.format(accuracy))\n",
    "    \n",
    "    first_time = placed[1] / (placed[1] + misplaced[1] + discarded[1])\n",
    "    print('Items placed correctly first time: {:.2}%'.format(first_time))\n",
    "    \n",
    "    print(ordered_info)\n",
    "    \n",
    "    print()\n",
    "    #real_data.log(env)\n",
    "    #env.logs = { 'placed':0, 'misplaced':0, 'discarded':0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce86a0c",
   "metadata": {},
   "source": [
    "### 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373733f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.7.0\n",
    "!pip install gym\n",
    "!pip install keras\n",
    "!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BinPackingEnvironment1D import BinPacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943020e4",
   "metadata": {},
   "source": [
    "### 2. Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db620665",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BinPacking(num_bins=10, capacity=20, min_item_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ff686",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a42ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664f65c7",
   "metadata": {},
   "source": [
    "### 3. Run baseline test (No ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67987518",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_STEPS = 1000\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    steps = 0\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done and steps < MAX_STEPS:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        steps += 1\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "    print(env.logs)\n",
    "    env.logs = { 'placed':0, 'misplaced':0, 'discarded':0 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626cf4eb",
   "metadata": {},
   "source": [
    "### 4. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0eaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e215b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will throw an error if these don't exist\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BinPacking(num_bins=10, capacity=20, min_item_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64aa48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167c320",
   "metadata": {},
   "source": [
    "### 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPO_Path = os.path.join('Training', 'Saved Models', 'Constant_PPO_Model_Discard_Penalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56cd2e",
   "metadata": {},
   "source": [
    "### 6. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa1370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39ee12",
   "metadata": {},
   "source": [
    "### 7. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb15c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_STEPS = 1000\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    steps = 0\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done and steps < MAX_STEPS:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        steps += 1\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "    print(env.logs)\n",
    "    env.logs = { 'placed':0, 'misplaced':0, 'discarded':0 }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
